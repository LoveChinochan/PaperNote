# UniVLA 统一VLA模型
## 传统VLA缺点
以语言为中心，将视觉投影至语义空间，再基于语言的表示，导出动作策略。这种的优势在于能够很好地理解语言指令，也能够很好地泛化。（因为用的是语言的抽象表示）

但也有缺点。视觉、语言、动作本质上是不同的模态，视觉包含高维、连续的空间信号；语言传达抽象的、离散的语义；动作是具有因果以来关系的时间有序序列。

现有VLA是处理静态的图像，以语言为中心，忽略了视觉和动作的动态性和因果性。
## 贡献
一个统一的VLA模型，共享词汇表中的离散token，自回归序列学习联合建模它们。
## 总体流程
![](https://i.postimg.cc/4N2ZWS5b/20250702165741.png)
视觉、语言和动作全都被转换成离散的tokens，使用共享的词汇表。统一的token表示允许跨模态的联合学习，从而促进更深入的跨模态理解和整合。

采用自回归基于马尔科夫链的序列建模方法，输入为视觉和动作交错（视觉->动作->下一步视觉->下一步动作->），是的自然构成了因果依赖关系，模型能够对时间动态进行推理，而不是将感知和动作视为孤立的任务。

训练期间采用大规模机器人视频进行自监督学习，可以使模型能够以时间一致且因果关系明确的方式捕捉环境动态。

`利用输入序列预测下一个，利用输入视频的前后帧构造标签`

## 两类方法
### 动作预测为核心
示例：RT-2、OpenVLA、RT-H 等

优点：

与已有的视觉-语言模型（VLMs）兼容性好，比如使用 transformer + token 自回归结构；

可以直接进行离散动作生成，易于部署。

缺点：

只关注“输入图像 → 输出动作”的映射；

缺乏对视觉空间结构的深入理解（如物体位置、目标状态）；

无法显式建模未来环境变化，无法做“如果我这么做，会看到什么”的推理。

### 视觉预测为核心
示例：SuSIE、UniPi、PAD、LAPA 等

优点：

能预测未来视觉帧 → 拥有因果推理与长时规划能力；

更适合建模连续状态的变化，提升对动态环境的理解。

缺点：

需要额外的视觉生成模块（如 VQ-VAE、Diffusion）；

视觉生成和动作预测往往是两个模块，难以端到端联合训练；

模型结构复杂，无法充分继承 VLM 的语义理解能力。
### 本文的方法将二者统一，优势相结合

## 具体细节
### 统一多模态模型
将语言、视觉和动作模态转换为离散的token并将其连接成一个单一的多模态序列L，从而统一了这三种模态。 $L_t$ 、 $L_v$ 、 $L_a$ 分别表示语言、视觉和动作的离散token序列，它们都来自一个共享的词汇表。上标是时间步长，token在不同模态间交错排列，保证时间对齐。

操作任务进行时，仅在开始提供文本指令，随后是视觉观察和动作的自然交错序列。文本使用与Emu3相同的tokenizer；视觉使用VQ-VAE进行离散化；动作使用FAST进行编码，并添加图像和动作的开始和结束标记。

`FAST是将动作信号使用DCT进行频域展开，DCT系数向量映射到一个离散词汇表（codebook）中的最近向量从而实现离散化，且去掉了无关紧要的频率部分，减少了token`

`VQ-VAE主要过程是图像经过CNN，提取出一个多维的连续特征向量，再进行量化，量化至距离最近的codebook向量`

由于是离散token，从而使用交叉熵损失函数预测下一个token。

### 统一多模态序列建模
使用MDP：状态 $s_t$ ：机器人在时刻 $t$ 的观察（图像）; 
动作 $a_t$ ：机器人要做什么（执行）; 
状态转移 $s_{t+1}$ ：动作执行后的新状态。

这种交错马尔可夫，将任务统一在一个共享的序列建模框架中，不再需要每个任务单独设计模型；可以在不同任务间共享表示、迁移知识、统一训练。

将语言指令也视为一种广义的动作形式，因为语言指令会影响状态的转移，可作为未来行为的一种先验指定。

世界模型下，无需与环境直接交互下推断结果（模拟式训练，不需要真实交互），给定当前观测 $L_v^1$ 和指令 $L_t^1$ ，预测未来的视觉内容，仅使用视觉tokens计算出的损失作为监督，使模型生成给定指令和观测状态为条件的视觉预测，将世界建模视为一种通用的视觉学习任务。形如 $S_v = { L_t^1, L_v^1, L_v^2 , \dots ,L_v^t }$

策略学习（微调）：策略学习使智能体能够基于当前观察和先前状态来确定最佳行动，从而有效地指导任务执行，改进特定于任务的行为。采用仅从动作令牌计算的损失函数。形如 $S_a = { L_t^1, L_v^1,L_a^1, L_v^2,L_a^2, \dots ,L_v^t,L_a^t }$

## 实验
### 数据集
CALVIN模拟基准。包含四个模拟环境，每个环境都有人工遥控操作收集的演示轨迹。包含34个不同任务，共有1000条独特的语言指令。性能使用序列中成功完成子任务的平均数量来衡量。

LIBERO基准测试。包含4个任务组，每个组保安10个任务和50个人工演示。这些任务评估泛化能力。LIBERO-Spatial 通过改变具有固定物体的布局来测试空间推理；LIBERO-Object 通过在固定场景中改变物体来评估物体级别的泛化能力；LIBERO-Goal 通过改变任务目标来针对目标条件行为；LIBERO-Long (LIBERO-10) 具有长时程、组合任务，包含不同的物体、布局和目标，挑战时间和组合推理。

SimplerEnv模拟基准。用于评估在真实世界视频数据上训练的模型的迁移性和泛化能力。

### 过程
采用纯自回归Transformer，8.5B参数。图像使用VQ图像编码器，空间压缩因子为8。动作编码使用连续帧间的相对差异，使用第1和第99百分位数进行归一化，然后使用FAST，词本大小为1024，并替换语言分词器的最后1024个token ID。

后训练阶段。使用机器人为中心的视频来进行后训练策略对下游策略学习的影响。在训练期间，监督仅应用于视觉tokens。该模型以64的批次大小训练30K步。

`大概就是使用语言和图像，自回归地生成下一帧图像。然后使用真实图像进行交叉熵损失的监督。`

微调阶段。UniVLA 以后训练的权重为初始化，采用“视觉-动作交错序列”输入，并仅在动作 token 上计算 loss，在多个机器人操作基准（如 CALVIN、LIBERO、SimplerEnv）上通过统一多模态输入进行策略训练，最终达到强泛化能力和任务执行效果。（仅关注语言+图像能否正确重构动作序列）

### 结果
在长程任务和多任务学习上表现优异。

大多数后训练方法显著增强了策略学习，突出了视觉学习在可迁移性中的关键作用。

在CALVIN基准测试中，仅使用10%的微调数据即可实现更高的成功率，优于GR-1和RoboVLMs等先前方法。

历史上下文的有效性，最近的观察结果具有最高的预测价值，这与顺序规划中的马尔可夫性质一致。

## 在自动驾驶的拓展应用
直接在NAVSIM基准上微调，迁移到自动驾驶。将驾驶任务建模为离散多模态令牌上的因果序列预测，仅使用前视摄像头输入，不依赖BEV或多传感器融合，就在NAVSIM测试集上实现了强大的性能。而且没有在驾驶视频上进行预训练，仅在下游策略基准上进行微调。
![](https://i.postimg.cc/8PwbsxMg/20250702165441.png)
