# UniVLA 统一VLA模型
## 传统VLA缺点
以语言为中心，将视觉投影至语义空间，再基于语言的表示，导出动作策略。这种的优势在于能够很好地理解语言指令，也能够很好地泛化。（因为用的是语言的抽象表示）

但也有缺点。视觉、语言、动作本质上是不同的模态，视觉包含高维、连续的空间信号；语言传达抽象的、离散的语义；动作是具有因果以来关系的时间有序序列。

现有VLA是处理静态的图像，以语言为中心，忽略了视觉和动作的动态性和因果性。
## 贡献
一个统一的VLA模型，共享词汇表中的离散token，自回归序列学习联合建模它们。
## 总体流程
视觉、语言和动作全都被转换成离散的tokens，使用共享的词汇表。统一的token表示允许跨模态的联合学习，从而促进更深入的跨模态理解和整合。

采用自回归基于马尔科夫链的序列建模方法，输入为视觉和动作交错（视觉->动作->下一步视觉->下一步动作->），是的自然构成了因果依赖关系，模型能够对时间动态进行推理，而不是将感知和动作视为孤立的任务。

训练期间采用大规模机器人视频进行自监督学习，可以使模型能够以时间一致且因果关系明确的方式捕捉环境动态。
'利用输入序列预测下一个，利用输入视频的前后帧构造标签'
